name: "latentnerf-wonormal"
tag: "debug"
exp_root_dir: "outputs"
seed: 0

data_type: "random-camera-datamodule"
data:
  eval_height: 64
  eval_width: 64

system_type: "latentnerf-system"
system:
  geometry_type: "implicit-volume"
  geometry:
    n_feature_dims: 4
    normal_type: null
    mlp_network_config:
      otype: "VanillaMLP"
      activation: "ReLU"
      output_activation: "none"
      n_neurons: 64
      n_hidden_layers: 1

  material_type: "no-material"
  
  # background_type: "solid-color-background"
  background_type: "neural-environment-map-background"
  background:
    n_output_dims: 4
    color_activation: tanh

  renderer_type: "nerf-volume-renderer"
  renderer:
    num_samples_per_ray: 512
  
  prompt_processor_type: "dreamfusion-prompt-processor"
  prompt_processor:
    prompt: "a hamburger"
  
  guidance_type: "stable-diffusion-guidance"
  guidance:
    half_precision_weights: true
    guidance_scale: 100.
    grad_clip: null
  
  loss:
    lambda_sds: 1.
    lambda_orient: 0.0
    lambda_sparsity: 0.0
    lambda_opaque: 0.0
  optimizer:
    name: Adam
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-15
  scheduler:
    name: SequentialLR
    interval: step
    warmup_steps: 100
    milestones:
      - ${system.scheduler.warmup_steps}
    schedulers:
      - name: LinearLR # linear warm-up in the first system.warmup_steps steps
        args:
          start_factor: 0.1
          end_factor: 1.0
          total_iters: ${system.scheduler.warmup_steps}
      - name: ExponentialLR
        args:
          gamma: ${calc_exp_lr_decay_rate:0.1,${sub:${trainer.max_steps},${system.scheduler.warmup_steps}}}

trainer:
  max_steps: 10000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 1000
  limit_val_batches: 1
  enable_progress_bar: true
  precision: 16-mixed

checkpoint:
  save_last: true
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
